{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pandas import DataFrame,Series\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import gc\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=pd.read_csv('data/atec_anti_fraud_train.csv')\n",
    "test = pd.read_csv('data/atec_anti_fraud_test_b.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.sort_values(by='date',inplace=True)\n",
    "\n",
    "train_x.drop(\"id\",axis=1,inplace=True)\n",
    "train_x.loc[train_x['label']==-1,'label']=1\n",
    "\n",
    "train_y=train_x[\"label\"]\n",
    "train_x.drop(\"label\",axis=1,inplace=True)\n",
    "\n",
    "test_id=test[\"id\"].copy()\n",
    "test.drop(\"id\",axis=1,inplace=True)\n",
    "\n",
    "train_size = len(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = train_x.append(test) \n",
    "del train_x,test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#筛选之后剩下的需要使用的特征\n",
    "col_need=['f1', 'f2', 'f3', 'f4', 'f6', 'f7', 'f8', 'f9', 'f11',\n",
    "       'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f161',\n",
    "       'f162', 'f163', 'f164', 'f165', 'f211', 'f212', 'f213', 'f214',\n",
    "       'f215', 'f216', 'f217', 'f218', 'f219', 'f220', 'f221', 'f222',\n",
    "       'f223', 'f224', 'f225', 'f226', 'f227', 'f228', 'f229', 'f230',\n",
    "       'f231', 'f232', 'f233', 'f234', 'f235', 'f236', 'f237', 'f238',\n",
    "       'f239', 'f240', 'f241', 'f242', 'f243', 'f244', 'f245', 'f246',\n",
    "       'f247', 'f248', 'f249', 'f250', 'f251', 'f252', 'f253']\n",
    "\n",
    "#这个函数用于将其余的不需要的特征列删除\n",
    "def preprocess_likeo(df,col_need):\n",
    "    num =0\n",
    "    drop_cols=[]\n",
    "    for col in df.columns:\n",
    "        if(col not in col_need):    \n",
    "            drop_cols.append(col)\n",
    "            num= num +1\n",
    "    df.drop(drop_cols,axis=1,inplace=True)\n",
    "    print('drop ',num, \" features in data set\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drop  233  features in data set\n"
     ]
    }
   ],
   "source": [
    "all_data = preprocess_likeo(all_data,col_need)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分别使用均值填充，插值填充和判定是否空值的方式填充连续型特征\n",
    "def mean_fillna(df,features):\n",
    "    for feature in features:\n",
    "        df[feature+'_mean']=df[feature].fillna(df[feature].mean())\n",
    "    return df\n",
    "\n",
    "def interpolate_fillna(df,features):\n",
    "    for feature in features:\n",
    "        df[feature]=df[feature].interpolate()\n",
    "    return df\n",
    "        \n",
    "def isnan_fillna(df,features):\n",
    "    for feature in features:\n",
    "        df[feature+'_isnan']=df[feature]\n",
    "        df.loc[(df[feature].isnull()),feature+'_isnan']=1\n",
    "        df.loc[(df[feature].notnull()),feature+'_isnan']=0\n",
    "    return df\n",
    "def median_fillna(df,features):\n",
    "    for feature in features:\n",
    "        df[feature+'_meadian']=df[feature].median()\n",
    "    return df\n",
    "\n",
    "#连续特征的处理方式\n",
    "def continues_fillna(df,features):\n",
    "    df=median_fillna(df,features)\n",
    "    #df=interpolate_fillna(df,features)\n",
    "    return df\n",
    "\n",
    "\n",
    "#使用-1填充离散型特征，并生成是否为空的特征列\n",
    "def category_fillna(df,category_cols):\n",
    "    for category_col in category_cols:\n",
    "        df[category_col].fillna(-1,inplace=True)\n",
    "    return df\n",
    "\n",
    "#为train和test数据标记是否是离散值，当数据unquie唯一值个数超过threld的时候，则被认为是连续特征，否则是离散特征。\n",
    "#并且填充缺失值\n",
    "def set_cate_type_and_fillna(train_x,test,threld=80):\n",
    "    #给离散列转换类型,得到离散值\n",
    "    data_clo_unique_num=pd.DataFrame(train_x.apply(lambda x:len(x.unique())),columns=['unique'])\n",
    "    for i in data_clo_unique_num.index:\n",
    "        print(i,\" \",data_clo_unique_num.loc[i,'unique'])\n",
    "    cate_cols=set(data_clo_unique_num[data_clo_unique_num['unique']<threld].index)\n",
    "    cont_cols=set(train_x.columns)-cate_cols\n",
    "    for i in cate_cols:\n",
    "        train_x=train_x.astype('category')\n",
    "        test=test.astype('category') \n",
    "    train_x=category_fillna(train_x,cate_cols)\n",
    "    test=category_fillna(test,cate_cols)\n",
    "    train_x=continues_fillna(train_x,cont_cols)\n",
    "    test=continues_fillna(test,con_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = all_data[:train_size]\n",
    "test = all_data[train_size:]\n",
    "del all_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size of train set is 994731, the size of test set is 500538\n",
      "f1   3\n",
      "f2   3\n",
      "f3   3\n",
      "f4   3\n",
      "f6   5\n",
      "f7   8\n",
      "f8   3\n",
      "f9   3\n",
      "f11   3\n",
      "f12   3\n",
      "f13   3\n",
      "f14   3\n",
      "f15   3\n",
      "f16   3\n",
      "f17   3\n",
      "f18   3\n",
      "f19   3\n",
      "f161   195\n",
      "f162   255\n",
      "f163   251\n",
      "f164   250\n",
      "f165   195\n",
      "f211   196\n",
      "f212   256\n",
      "f213   238\n",
      "f214   251\n",
      "f215   292\n",
      "f216   303\n",
      "f217   303\n",
      "f218   303\n",
      "f219   32\n",
      "f220   33\n",
      "f221   33\n",
      "f222   33\n",
      "f223   135\n",
      "f224   159\n",
      "f225   157\n",
      "f226   161\n",
      "f227   252\n",
      "f228   249\n",
      "f229   255\n",
      "f230   187\n",
      "f231   258\n",
      "f232   256\n",
      "f233   256\n",
      "f234   273\n",
      "f235   303\n",
      "f236   303\n",
      "f237   396\n",
      "f238   667\n",
      "f239   78\n",
      "f240   276\n",
      "f241   274\n",
      "f242   278\n",
      "f243   281\n",
      "f244   249\n",
      "f245   303\n",
      "f246   295\n",
      "f247   303\n",
      "f248   342\n",
      "f249   160\n",
      "f250   278\n",
      "f251   253\n",
      "f252   268\n",
      "f253   275\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "fill value must be in categories",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-ad557540bd4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"the size of train set is \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\", the size of test set is \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mset_cate_type_and_fillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-85ddf2130a0d>\u001b[0m in \u001b[0;36mset_cate_type_and_fillna\u001b[0;34m(train_x, test, threld)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mtrain_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mtrain_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategory_fillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcate_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategory_fillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcate_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mtrain_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontinues_fillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcont_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-85ddf2130a0d>\u001b[0m in \u001b[0;36mcategory_fillna\u001b[0;34m(df, category_cols)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcategory_fillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcategory_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcategory_col\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcategory_cols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcategory_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py35/lib/python3.5/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mfillna\u001b[0;34m(self, value, method, axis, inplace, limit, downcast, **kwargs)\u001b[0m\n\u001b[1;32m   3836\u001b[0m                                           \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3837\u001b[0m                                           \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdowncast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdowncast\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3838\u001b[0;31m                                           **kwargs)\n\u001b[0m\u001b[1;32m   3839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3840\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shared_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'replace'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0m_shared_doc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py35/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mfillna\u001b[0;34m(self, value, method, axis, inplace, limit, downcast)\u001b[0m\n\u001b[1;32m   6102\u001b[0m                 new_data = self._data.fillna(value=value, limit=limit,\n\u001b[1;32m   6103\u001b[0m                                              \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6104\u001b[0;31m                                              downcast=downcast)\n\u001b[0m\u001b[1;32m   6105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6106\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py35/lib/python3.5/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mfillna\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fillna'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdowncast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py35/lib/python3.5/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m                                             copy=align_copy)\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py35/lib/python3.5/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mfillna\u001b[0;34m(self, value, limit, inplace, downcast)\u001b[0m\n\u001b[1;32m   1832\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdowncast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1833\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1834\u001b[0;31m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1835\u001b[0m         return [self.make_block_same_class(values=values,\n\u001b[1;32m   1836\u001b[0m                                            \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py35/lib/python3.5/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py35/lib/python3.5/site-packages/pandas/core/arrays/categorical.py\u001b[0m in \u001b[0;36mfillna\u001b[0;34m(self, value, method, limit)\u001b[0m\n\u001b[1;32m   1782\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1784\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fill value must be in categories\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcodes\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: fill value must be in categories"
     ]
    }
   ],
   "source": [
    "print(\"the size of train set is \"+str(train_x.shape[0])+\", the size of test set is \"+str(test.shape[0]))\n",
    "set_cate_type_and_fillna(train_x,test,80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#评价函数，可用于普通的sklearn包算法的结果分析，如GBDT\n",
    "def feval_spec(preds, train_data):\n",
    "    from sklearn.metrics import roc_curve\n",
    "    fpr, tpr, threshold = roc_curve(train_data, preds)\n",
    "    tpr0001 = tpr[fpr <= 0.001].max()\n",
    "    tpr001 = tpr[fpr <= 0.005].max()\n",
    "    tpr005 = tpr[fpr <= 0.01].max()\n",
    "    #tpr01 = tpr[fpr.values <= 0.01].max()\n",
    "    tprcal = 0.4 * tpr0001 + 0.3 * tpr001 + 0.3 * tpr005\n",
    "    return tprcal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用于lightgbm的评价函数\n",
    "def feval_spec_train(preds, train_data):\n",
    "    from sklearn.metrics import roc_curve\n",
    "    fpr, tpr, threshold = roc_curve(train_data.get_label(), preds)\n",
    "    tpr0001 = tpr[fpr <= 0.001].max()\n",
    "    tpr001 = tpr[fpr <= 0.005].max()\n",
    "    tpr005 = tpr[fpr <= 0.01].max()\n",
    "    #tpr01 = tpr[fpr.values <= 0.01].max()\n",
    "    tprcal = 0.4 * tpr0001 + 0.3 * tpr001 + 0.3 * tpr005\n",
    "    return 'spec_cal',tprcal,True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kfolds将数据根据索引分为k份，可以用于生成第一层输出的时候，保证各折数据之间没有干扰\n",
    "# GroupSelect将Kfolds中的第i折数据索引作为预测集pre_set，其余的作为训练集train_set。\n",
    "# TrainSet针对训练数据的i折，得到训练数据和第二层的输入数据\n",
    "def Kfolds(x_index,k=5,seed=1):\n",
    "    np.random.seed(seed)\n",
    "    xL=np.array_split(np.random.choice(x_index,len(x_index),replace=False),k)\n",
    "    return xL\n",
    "\n",
    "def GroupSelect(xL,i=0):\n",
    "    xLc=xL.copy()\n",
    "    pre_index=list(xLc.pop(i))\n",
    "    train_index=sum([list(x) for x in xLc],[])\n",
    "    return train_index,pre_index\n",
    "\n",
    "def TrainSet(x,y,xL,i=0):\n",
    "    train_index,pre_index=GroupSelect(xL,i)\n",
    "    train_x,pre_x=x.loc[train_index],x.loc[pre_index]\n",
    "    train_y,pre_y=y.loc[train_index],y.loc[pre_index]\n",
    "    return train_x,train_y,pre_x,pre_y\n",
    "\n",
    "#K折交叉验证，可用于sklearn传统机器学习算法\n",
    "def KflodsTrain(x,y,test,k=5,classifier=lgb.LGBMClassifier()):\n",
    "    xL=Kfolds(np.array(x.index),k)\n",
    "    #predict_proba=pd.DataFrame()\n",
    "    test_predict_proba=pd.DataFrame()\n",
    "    for i in range(k):\n",
    "        print(\"begin the \"+str(i)+\" of \"+str(k)+\" kflods training...\")\n",
    "        train_x,train_y,pre_x,pre_y=TrainSet(x,y,xL,i)\n",
    "        model=classifier.fit(train_x,train_y)\n",
    "        predict_res=pd.Series(model.predict_proba(pre_x)[:, 1],index=pre_x.index)\n",
    "        train_metric=feval_spec(model.predict_proba(train_x)[:,1],train_y)\n",
    "        valid_metri=feval_spec(predict_res,pre_y)\n",
    "        print(\"The \",i,\" times res: train set spe_val:\",train_metric,\", validation set sep_val: \",valid_metri)\n",
    "        #predict_proba=pd.concat([predict_proba,predict_res])\n",
    "        test_predict_proba=pd.Series(model.predict_proba(test)[:,1],index=test.index)\n",
    "    #print(\"The output data of classifier: \",type(classifier), \" is ready for stacking...\")\n",
    "    #print(\"the size  of data is \",predict_proba.shape[0])\n",
    "    test_predict_proba_mean=test_predict_proba.mean(axis=1)\n",
    "    return test_predict_proba_mean\n",
    "\n",
    "#K折交叉验证算法，用于lightgbm算法\n",
    "def KflodsTrain_light(x,y,test,k=5,lgb_params=None):\n",
    "    if lgb_params==None:\n",
    "        lgb_params = {\n",
    "            'boosting_type': 'gbdt', \n",
    "            'objective': 'binary', \n",
    "            'nthread': -1, \n",
    "            'metric': 'auc',\n",
    "            'num_leaves': 7,  # -1 means no limit\n",
    "            'min_child_samples': 1000,  # Minimum number of data need in a child(min_data_in_leaf)  \n",
    "        }\n",
    "    xL=Kfolds(np.array(x.index),k)\n",
    "    #predict_proba=pd.DataFrame()\n",
    "    test_predict_proba=pd.DataFrame()\n",
    "    for i in range(k):\n",
    "        print(\"begin the \"+str(i)+\" of \"+str(k)+\" kflods training...\")\n",
    "        train_x,train_y,pre_x,pre_y=TrainSet(x,y,xL,i)\n",
    "        xgtrain = lgb.Dataset(train_x,train_y)\n",
    "        xgvalid = lgb.Dataset(pre_x,pre_y)\n",
    "        evals_results={}\n",
    "        bst1 = lgb.train(lgb_params,xgtrain,valid_sets=[xgtrain,xgvalid],valid_names=['train','valid'],evals_result=evals_results,\n",
    "                    num_boost_round=200,early_stopping_rounds=30, verbose_eval=False,feval=feval_spec_train)        \n",
    "        print('The ',i,' times running....')\n",
    "        print('Best ite and score ',bst1.best_iteration,bst1.best_score)\n",
    "        #predict_proba=pd.concat([predict_proba,predict_res])\n",
    "        test_predict_proba=pd.Series(bst1.predict(test,num_iteration=bst1.best_iteration),index=test.index)\n",
    "        \n",
    "    #print(\"The output data of classifier: \",type(classifier), \" is ready for stacking...\")\n",
    "    #print(\"the size  of data is \",predict_proba.shape[0])\n",
    "    print(test_predict_proba)\n",
    "    return test_predict_proba\n",
    "#     test_predict_proba_mean=test_predict_proba.mean(axis=1)\n",
    "#     return test_predict_proba_mean\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#设置lightgbm参数之后，调用上面的方法即可\n",
    "total_res=pd.DataFrame()\n",
    "total_res['id']=test_id\n",
    "lgb_params = {\n",
    "            'boosting_type': 'gbdt', \n",
    "            'objective': 'binary', \n",
    "            'nthread': -1, \n",
    "            'metric': 'auc',\n",
    "            'bagging_fraction':0.8,\n",
    "            'feature_fraction':0.8,\n",
    "            'num_leaves': 250,  # -1 means no limit\n",
    "            'min_child_samples': 100,  # Minimum number of data need in a child(min_data_in_leaf)  \n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin the 0 of 10 kflods training...\n",
      "The  0  times running....\n",
      "Best ite and score  42 defaultdict(<class 'dict'>, {'valid': {'auc': 0.9517678597534437, 'spec_cal': 0.3059649122807018}, 'train': {'auc': 0.9730200833072992, 'spec_cal': 0.42521635727026497}})\n",
      "begin the 1 of 10 kflods training...\n",
      "The  1  times running....\n",
      "Best ite and score  39 defaultdict(<class 'dict'>, {'valid': {'auc': 0.9514489389023241, 'spec_cal': 0.2954545454545454}, 'train': {'auc': 0.9710313006638056, 'spec_cal': 0.42190325348115887}})\n",
      "begin the 2 of 10 kflods training...\n",
      "The  2  times running....\n",
      "Best ite and score  62 defaultdict(<class 'dict'>, {'valid': {'auc': 0.9465062185011118, 'spec_cal': 0.2848414985590778}, 'train': {'auc': 0.9834448957546803, 'spec_cal': 0.46703943885653787}})\n",
      "begin the 3 of 10 kflods training...\n",
      "The  3  times running....\n",
      "Best ite and score  44 defaultdict(<class 'dict'>, {'valid': {'auc': 0.9505816389046823, 'spec_cal': 0.289512893982808}, 'train': {'auc': 0.9738251245096424, 'spec_cal': 0.4331876572639385}})\n",
      "begin the 4 of 10 kflods training...\n",
      "The  4  times running....\n",
      "Best ite and score  59 defaultdict(<class 'dict'>, {'valid': {'auc': 0.9505012567778572, 'spec_cal': 0.3055225653206651}, 'train': {'auc': 0.9823008518311208, 'spec_cal': 0.46292290443843565}})\n",
      "begin the 5 of 10 kflods training...\n",
      "The  5  times running....\n",
      "Best ite and score  54 defaultdict(<class 'dict'>, {'valid': {'auc': 0.95027330513379, 'spec_cal': 0.3025950512975256}, 'train': {'auc': 0.9796135528808545, 'spec_cal': 0.450329163923634}})\n",
      "begin the 6 of 10 kflods training...\n",
      "The  6  times running....\n",
      "Best ite and score  53 defaultdict(<class 'dict'>, {'valid': {'auc': 0.9484353743801862, 'spec_cal': 0.30556213017751477}, 'train': {'auc': 0.9791629035500369, 'spec_cal': 0.44929735435772256}})\n",
      "begin the 7 of 10 kflods training...\n",
      "The  7  times running....\n",
      "Best ite and score  31 defaultdict(<class 'dict'>, {'valid': {'auc': 0.9504523430559206, 'spec_cal': 0.28867699642431466}, 'train': {'auc': 0.965473037138802, 'spec_cal': 0.40083064143977853}})\n",
      "begin the 8 of 10 kflods training...\n",
      "The  8  times running....\n",
      "Best ite and score  51 defaultdict(<class 'dict'>, {'valid': {'auc': 0.9494439152470495, 'spec_cal': 0.2941212121212121}, 'train': {'auc': 0.9786414626337161, 'spec_cal': 0.45268803053234186}})\n",
      "begin the 9 of 10 kflods training...\n",
      "The  9  times running....\n",
      "Best ite and score  53 defaultdict(<class 'dict'>, {'valid': {'auc': 0.9489629618135026, 'spec_cal': 0.31290523690773064}, 'train': {'auc': 0.9782910332273762, 'spec_cal': 0.4492750770845634}})\n",
      "0         0.011595\n",
      "1         0.000486\n",
      "2         0.001644\n",
      "3         0.017257\n",
      "4         0.012974\n",
      "5         0.001232\n",
      "6         0.003377\n",
      "7         0.002759\n",
      "8         0.002471\n",
      "9         0.033082\n",
      "10        0.016266\n",
      "11        0.000390\n",
      "12        0.442586\n",
      "13        0.005395\n",
      "14        0.028327\n",
      "15        0.001397\n",
      "16        0.009826\n",
      "17        0.001465\n",
      "18        0.004203\n",
      "19        0.004877\n",
      "20        0.001301\n",
      "21        0.006057\n",
      "22        0.002086\n",
      "23        0.004843\n",
      "24        0.270077\n",
      "25        0.000387\n",
      "26        0.014371\n",
      "27        0.000843\n",
      "28        0.001758\n",
      "29        0.009032\n",
      "            ...   \n",
      "500508    0.002008\n",
      "500509    0.002750\n",
      "500510    0.002876\n",
      "500511    0.000333\n",
      "500512    0.000902\n",
      "500513    0.010478\n",
      "500514    0.001790\n",
      "500515    0.000661\n",
      "500516    0.003660\n",
      "500517    0.000705\n",
      "500518    0.013309\n",
      "500519    0.000302\n",
      "500520    0.001707\n",
      "500521    0.000709\n",
      "500522    0.002041\n",
      "500523    0.032910\n",
      "500524    0.002441\n",
      "500525    0.005989\n",
      "500526    0.005014\n",
      "500527    0.001336\n",
      "500528    0.005451\n",
      "500529    0.018097\n",
      "500530    0.008827\n",
      "500531    0.004817\n",
      "500532    0.000341\n",
      "500533    0.036899\n",
      "500534    0.001751\n",
      "500535    0.007864\n",
      "500536    0.014850\n",
      "500537    0.001783\n",
      "Length: 500538, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "total_res[\"score\"]=KflodsTrain_light(train_x,train_y,test,10,lgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_res.to_csv(\"submission_1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
